# Using GPU enabled NMF to learn spectral features(W) and temporal activations(H) in an unsupervised manner
import torch
from pytorchNMF.torchnmf import NMF
import numpy as np
import numpy.matlib
import matplotlib.pyplot as plt
import matplotlib.cm as cm
from soundscape_IR.soddsundscape_viewer.utility import save_parameters
from soundscape_IR.soundscape_viewer.utility import gdrive_handle
from scipy.io import loadmat
from scipy.io import savemat
from sklearn.decomposition import non_negative_factorization as NMF_cpu


class nmf_gpu:
  def __init__(self, feature_length=1, basis_num=60):
      self.basis_num=basis_num
      self.feature_length=feature_length

  #def feature_learning(self, input_data, f, alpha=1, l1_ratio=1, max_iter=200, beta=1, kernel='gpu'):    
  def feature_learning(self, input_data, f, max_iter=200, beta=2, sW=None, sH=None, kernel='gpu'):
      # Preparing data
      self.f=f
      self.time_vec=input_data[:,0:1]
      input_data=input_data[:,1:].T
      baseline=input_data.min()
      input_data=input_data-baseline
      print('Run NMF')
      
      # Modify the input data based the feature width
      if self.feature_length>1:
        input_data=self.matrix_conv(input_data)

      print('Feature learning...')
      if kernel=='gpu':
        # NMF-based feature learning
        data = torch.FloatTensor(input_data)
        net = NMF(data.shape, rank=self.basis_num).cuda()
        #net.fit_transform(data.cuda(), verbose=True, max_iter=max_iter, tol=1e-18, alpha=alpha, l1_ratio=l1_ratio, beta=beta)
        net.fit_transform(data.cuda(), verbose=True, max_iter=max_iter, beta=beta, sW=sW, sH=sH, sparse=True)
        self.W, self.H = net.W.detach().cpu().numpy(), net.H.detach().cpu().numpy()
        data = data.detach().cpu()
      elif kernel=='cpu':
        self.W, self.H, _ = NMF_cpu(input_data, n_components=self.basis_num, beta_loss=beta, alpha=alpha, l1_ratio=l1_ratio) 

      print('Done')

  def reconstruct(self):
      output = np.dot(self.W, self.H)
      temp=np.zeros((len(self.f), self.H.shape[1]+1-self.feature_length))
      for x in range(self.feature_length):
        #temp=temp+output[x*len(self.f):(x+1)*len(self.f),x:self.H.shape[1]+1-self.feature_length+x]
        temp=temp+output[(self.feature_length-(x+1))*len(self.f):(self.feature_length-x)*len(self.f),x:self.H.shape[1]+1-self.feature_length+x]
      output=np.divide(temp,self.feature_length)
      output[np.isnan(output)]=0
      return output
      
  def matrix_conv(self, input_data):
      # Adding time-series information for each vector
      matrix_shape=input_data.shape
      data=np.zeros((matrix_shape[0]*self.feature_length, matrix_shape[1]-1+self.feature_length))
      for x in range(self.feature_length):
        data[(self.feature_length-(x+1))*matrix_shape[0]:(self.feature_length-x)*matrix_shape[0],x:matrix_shape[1]+x]=input_data
      return data

  def plot_nmf(self, plot_type='Both', W_list=None):
      # Plot the spectral features(W) and temporal activations(H) learned by using the NMF
      W=np.array(self.W)
      W_num=W.shape[1]
      if self.W.shape[0]>len(self.f):
        if isinstance(W_list,np.ndarray):
          W=np.array(W[:,W_list])
        W=np.vstack((np.zeros((len(self.f),W.shape[1])), W)).T.reshape(1,-1)
        W=W.reshape((-1,len(self.f))).T
      elif self.W.shape[0]==len(self.f):
        if W_list:
          W=W[:,W_list]
      
      if isinstance(W_list,np.ndarray):
        H=np.array(self.H[W_list,:])
      else:
        H=np.array(self.H)
        
      # plot the features
      if plot_type=='Both':
        fig, (ax1, ax2) = plt.subplots(nrows=2,figsize=(20, 12))
      elif plot_type=='W':
        fig, ax1 = plt.subplots(figsize=(300, 50))
      elif plot_type=='H':
        fig, ax2 = plt.subplots(figsize=(14, 6))

      if plot_type=='Both' or plot_type=='W':
        im = ax1.imshow(W, origin='lower',  aspect='auto', cmap=cm.jet, 
                        extent=[0, W_num, self.f[0], self.f[-1]], interpolation='none')
        ax1.set_title('W')
        ax1.set_ylabel('Frequency')
        ax1.set_xlabel('Basis')
        cbar1 = fig.colorbar(im, ax=ax1)
        cbar1.set_label('Relative amplitude')

      if plot_type=='Both' or plot_type=='H':
        im2 = ax2.imshow(H, origin='lower',  aspect='auto', cmap=cm.jet,
                        extent=[self.time_vec[0], self.time_vec[-1], 0, W_num], interpolation='none')
        ax2.set_title('H')
        ax2.set_ylabel('Basis')
        ax2.set_xlabel('Time')
        cbar2 = fig.colorbar(im2, ax=ax2)
        cbar2.set_label('Relative amplitude')

  def save_model(self, filename='NMF_model.mat', folder_id=[]):
      #import save_parameters
      nmf_model=save_parameters()
      nmf_model.supervised_nmf(self.f, self.W, self.feature_length, self.basis_num)
      savemat(filename, {'save_model':nmf_model})
      print('Successfully save to '+filename)
      
      # save the result in Gdrive as a mat file
      if folder_id:
        Gdrive=gdrive_handle(folder_id)
        Gdrive.upload(filename)

  def load_model(self, filename):
      model = loadmat(filename)
      self.f=model['save_model']['f'].item()[0]
      self.W=model['save_model']['W'].item()
      self.feature_length=model['save_model']['time_frame'].item()[0][0]
      self.basis_num=model['save_model']['basis_num'].item()[0][0]

class feature_reduction():
   def __init__(self, input, method):
     W = frame_normalization(input.W, axis=0)
     self.W=W
     #H = input.H
     f = input.f
     self.feature_length = input.feature_length
     self.basis_num = input.basis_num
     if method == 'freq':
       self.freq_cluster(W,f)

     elif method == 'fft':
       self.fft_cluster(W)

     elif method == 'h_seq':
       self.reshaped=self.matrix_reshape(W,f)

   def nmf_reduction(self, f, basis_num2=10, max_iter=200, beta=2, sW=None, sH=None, kernel='gpu'):
     model2=nmf_gpu(1,basis_num2)
     model2.feature_learning(self.reshaped, f, max_iter, beta, sW, sH, kernel)
     model2.plot_nmf(plot_type='Both')
     self.h2=model2.H
     self.basis_num2 = basis_num2
     self.h_seq_cluster(model2.H,1)
     

   #reshape matrix to run NMF
   def matrix_reshape(self,W,f):
     reshaped_w = W.T.reshape((-1,len(f)))
     basis_vector = np.arange(1, self.basis_num+1).repeat(self.feature_length)
     print(basis_vector)
     reshaped = np.hstack((basis_vector[:,None],reshaped_w))
     print(reshaped.shape)
     self.reshaped=reshaped
     return reshaped

   def freq_cluster(self,W,f):
     reshaped=self.matrix_reshape(W,f)
     for i in range(1,self.basis_num+1):
        if i==1:
           freq_distribution = np.mean(reshaped[reshaped[:,0]==i,1:],axis=0)
        else:
           freq_distribution = np.vstack((freq_distribution,np.mean(reshaped[reshaped[:,0]==i,1:],axis=0)))
     print(freq_distribution.shape)
     self.result = freq_distribution
      
   def fft_cluster(self,W): 
      import scipy
      from scipy.fft import fft
      import matplotlib.pyplot as plt
      (start,end)=(int(self.feature_length-(self.feature_length/4)),int(self.feature_length+(self.feature_length/4)))
      for i in range(self.basis_num):
        if i==0:
           matrix = np.log(np.abs(fft(W[:,i])[start:end]))
        else:
           matrix = np.vstack((matrix,np.log(np.abs(fft(W[:,i])[start:end]))))
        plt.plot(np.log(np.abs(fft(W[:,i])[start:end])))
      print(matrix.shape)
      self.result = matrix 

   def h_seq_cluster(self,H,feature_length):
     h=H[:,int(np.floor(feature_length/2)):self.feature_length*self.basis_num+int(np.floor(feature_length/2))]
     final = np.zeros(h.shape[0])
     for i in range(1,self.basis_num+1): 
       max_loc= np.argmax(h[:,self.reshaped[:,0]==i],axis=1) 
       a = np.sum(h[:,self.reshaped[:,0]==i], axis=1)
       index = a.argsort()[::-1]
       b = np.sum(a)
       answer = np.where(np.cumsum(np.sort(a)[::-1])>b*0.98)[0][0]
       max_loc[index[answer+1:]]=0
       t = abs(np.subtract(max_loc,50))
       t[np.where(max_loc==0)]=0
       t_index = np.argsort(t)[::-1]
       count = np.arange(self.basis_num2)[::-1]
       for j in range(0,answer+1):
         t[t_index[j]] = count[j]
       final = np.vstack((final,t))
     print(final[1:,])
     self.result = final[1:,]
       
   def cluster(self, explained_var, pca_percent=0.9, method='kmeans'):
     from soundscape_IR.soundscape_viewer import clustering
     cluster_result=clustering(k=explained_var, pca_percent=pca_percent, method=method)
     cluster_result.run(input_data=self.result, f=np.arange(1,self.result.shape[1])) #f=np.arange(1,self.result.shape[1]))f=np.linspace(4000, 25000, num=111)
     print(cluster_result.cluster)
     self.cluster_result=cluster_result.cluster
     self.cluster_object=cluster_result
     
       
   def view_clusters(self,cluster_num):
     self.cluster_object.plot_cluster_feature(cluster_no=cluster_num, freq_scale='linear', f_range=[], fig_width=12, fig_height=6)

  
   def examine_result(self):
     matrix=np.zeros((np.max(self.cluster_result),7))
     for i in range(1,np.max(self.cluster_result)+1):
       species=np.floor(np.where(self.cluster_result==i)[0]/100).astype(int)
       for j in species:
         percentage = 100/len(species)
         matrix[i-1][j] += percentage
     plot_spec(matrix,[0,np.max(self.cluster_result)],10,10,0.5,7.5,x_label='Species',y_label='Cluster')
